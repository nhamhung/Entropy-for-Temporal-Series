{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dispersion Entropy\n",
    "\n",
    "## Rationale\n",
    "- Sample Entropy, though powerful and broadly used in many signal + image-processing applications, is not fast enough,\n",
    "especially for long signals.\n",
    "- Permutation Entropy which is based on order relations among values of a signal, though conceptually simple and\n",
    "computationally fast, considers only the order of the amplitude values and\n",
    "hence some information regarding the amplitudes may be discarded (such as the mean value of amplitudes and differences between\n",
    "amplitude values).\n",
    "\n",
    "Introduce Dispersion Entropy:\n",
    "- Unlike Perm Ent, it can detect the noise bandwidth + simultaneous frequency + amplitude change.\n",
    "- Considerably outperforms PE to discriminate different groups of each dataset.\n",
    "- Computation time significantly less than SE and PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To appreciate the relevance and possible usefulness of DE in a number of signal analyses, it is important to understand\n",
    "behaviour of the technique for various kinds of classical signal concepts such as:\n",
    "- Amplitude\n",
    "- Frequency\n",
    "- Noise power\n",
    "- Signal bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Formula\n",
    "Given a univariate signal length N\n",
    "1. First, $x_j(j = 1,2,...,N)$ are mapped to $c$ classes, labelled from 1 to $c$. To do so, we employ a normal cumulative\n",
    "distribution function (NCDF) to map $x$ into $y = {y_1, y_2, ..., y_N}$ from 0 to 1. Next, we use a linear algorithm to\n",
    "assign each $y_j$ to an integer from 1 to $c$. To do so, we use $z^c_j = round(c.y_j + 0.5)$ where $z^c_j$ for each $j$.\n",
    "2. Each embedding vector $z^{m,c}_i$ with embedding dimension $m$ and time delay $d$ is created according to\n",
    "$z^{m,c}_i = \\{z^c_i, z^c_{i+d}, ..., z^c_{i+(m-1)d}\\}$, $i = 1,2,...,N-(m-1)d$. Each time series $z^{m,c}_i$ is mapped to\n",
    "a dispersion pattern $\\pi_{v_0 v_1 ... v_{m-1}}$. The number of possible dispersion patterns that can be assigned to each\n",
    "time series $z^{m,c}_i$ is equal to $c^m$, since the signal has $m$ members and each member can be one of the integers from\n",
    "1 to $c$.\n",
    "3. For each $c^m$ potential dispersion patterns, relative frequency is obtained as follows:\n",
    "$$p(\\pi_{v_0 v_1 ... v_{m-1}}) = \\frac{Number\\{i|i \\leq N - (m-1)d, z^{m,c}_i \\text{ has type } \\pi_{v_0 v_1 ... v_{m-1}}\\}}{N-(m-1)d}$$\n",
    "\n",
    "In other words, $p(\\pi_{v_0 v_1 ... v_{m-1}})$ shows the number of dispersion patterns $\\pi_{v_0 v_1 ... v_{m-1}}$ that\n",
    "are assigned to $z^{m,c}_i$, divided by total number of embedding signals with embedding dimension $m$.\n",
    "4. Finally, based on Shannon Entropy, DE with embedding dimension $m$, time delay $d$ and number of classes $c$ is:\n",
    "$$DE(x, m, c, d) = - \\sum^{c^m}_{\\pi=1}p(\\pi_{v_0 v_1 ... v_{m-1}}).ln(p(\\pi_{v_0 v_1 ... v_{m-1}}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define signal, c, m, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "signal = [9, 8, 1, 12, 5, -3, 1.5, 8.01, 2.99, 4, -1, 10]\n",
    "delay = 1\n",
    "embed = 2\n",
    "classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define ncdf_mapping to map signal into y from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82623478, 0.76305643, 0.19867004, 0.94619779, 0.51854591,\n",
       "       0.0409939 , 0.23123962, 0.76374496, 0.34377923, 0.42986535,\n",
       "       0.09803594, 0.87750645])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ncdf_mapping(signal):\n",
    "    length = len(signal)\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal) if np.std(signal) != 0 else 0.001\n",
    "    ncdf = norm(loc=mean, scale=std)\n",
    "    mapped_signal = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        mapped_signal[i] = ncdf.cdf(signal[i])\n",
    "    return mapped_signal\n",
    "\n",
    "ncdf_mapping(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Map each $y_j$ to an integer from 1 to $c$ using linear z function\n",
    "$$z^c_j = round(c.y_j + 0.5)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 1., 3., 2., 1., 1., 3., 2., 2., 1., 3.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(signal)\n",
    "mapped_signal = ncdf_mapping(signal)\n",
    "z_signal = np.round(classes * mapped_signal + 0.5)\n",
    "z_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We have $c^m$ possible dispersion patterns\n",
    "`3 ^ 2 = 9` $(\\pi_{11},\\pi_{12},\\pi_{13},\\pi_{21},\\pi_{22},\\pi_{23},\\pi_{31},\\pi_{32},\\pi_{33})$\n",
    "and $N - (m-1) * d = 12 - (2-1) = 11$ embedding vectors of length 2 and their associated dispersion patterns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispersions = np.zeros(classes ** embed)\n",
    "dispersions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Each embedding vector $z^{m,c}_i = \\{z^c_i, z^c_{i+d}, ..., z^c_{i+(m-1)d}\\}$ for $i = 1,2,...,N-(m-1)d$\n",
    "\n",
    "<img src=\"images/pic11.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector 1:  [3. 3.]\n",
      "Index:  8.0\n",
      "Embedding vector 2:  [3. 1.]\n",
      "Index:  6.0\n",
      "Embedding vector 3:  [1. 3.]\n",
      "Index:  2.0\n",
      "Embedding vector 4:  [3. 2.]\n",
      "Index:  7.0\n",
      "Embedding vector 5:  [2. 1.]\n",
      "Index:  3.0\n",
      "Embedding vector 6:  [1. 1.]\n",
      "Index:  0.0\n",
      "Embedding vector 7:  [1. 3.]\n",
      "Index:  2.0\n",
      "Embedding vector 8:  [3. 2.]\n",
      "Index:  7.0\n",
      "Embedding vector 9:  [2. 2.]\n",
      "Index:  4.0\n",
      "Embedding vector 10:  [2. 1.]\n",
      "Index:  3.0\n",
      "Embedding vector 11:  [1. 3.]\n",
      "Index:  2.0\n",
      "\n",
      "Frequency of each dispersion pattern:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 3., 2., 1., 0., 1., 2., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(length - (embed - 1) * delay):\n",
    "    tmp_pattern = z_signal[i:i + embed * delay:delay] # last :delay means the increment length\n",
    "    pattern_index = 0\n",
    "    print(f\"Embedding vector {i + 1}: \", tmp_pattern)\n",
    "    for idx, c in enumerate(reversed(tmp_pattern)):\n",
    "        c = classes if c == (classes + 1) else c\n",
    "        pattern_index += ((c - 1) * (classes ** idx))\n",
    "    print(\"Index: \" ,pattern_index)\n",
    "\n",
    "    dispersions[int(pattern_index)] += 1\n",
    "\n",
    "print(\"\\nFrequency of each dispersion pattern:\")\n",
    "dispersions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Calculate probability for each dispersion pattern:\n",
    "<img src=\"images/pic12.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09090909, 0.        , 0.27272727, 0.18181818, 0.09090909,\n",
       "       0.        , 0.09090909, 0.18181818, 0.09090909])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = dispersions / sum(dispersions)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Calculate dispersion entropy:\n",
    "$$DE(x, m, c, d) = - \\sum^{c^m}_{\\pi=1}p(\\pi_{v_0 v_1 ... v_{m-1}}).ln(p(\\pi_{v_0 v_1 ... v_{m-1}}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter out 0 prob: \n",
      " [0.09090909090909091, 0.2727272727272727, 0.18181818181818182, 0.09090909090909091, 0.09090909090909091, 0.18181818181818182, 0.09090909090909091]\n",
      "Dispersion entropy:  1.8462202193216335\n"
     ]
    }
   ],
   "source": [
    "probs = list(filter(lambda p: p != 0., probs))\n",
    "print(\"Filter out 0 prob: \\n\", probs)\n",
    "de = -1 * np.sum(probs * np.log(probs))\n",
    "print(\"Dispersion entropy: \", de)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
